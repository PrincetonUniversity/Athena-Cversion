\nonstopmode
\documentstyle[11pt]{article}

\setlength{\textheight}{9.0in}
\setlength{\textwidth}{6.5in}
\hoffset=-1.3 truecm
\voffset=-1.7 truecm

\newcommand{\SEP}[1]{\setlength{\fboxsep}{#1pt}}
\newsavebox{\Qbox}
\newenvironment{Ebox}{\hspace*{.1in}%
\begin{lrbox}{\Qbox}%
\begin{minipage}[t]{4.4in}\it\sffamily}%
{\end{minipage}%
\end{lrbox}\vspace{6pt}\SEP{6}%
\fbox{\usebox{\Qbox}}\vspace{6pt}\SEP{3}}



\newcommand{\ath}{{\tt athena3.0}}
\newcommand{\Dx}[0]{\bigtriangleup x}

\makeatletter                                            %KT
\@ifundefined{epsfbox}{\@input{epsf.sty}}{\relax}        %KT
\def\plotone#1{\centering \leavevmode                    %KT
\epsfxsize=\columnwidth \epsfbox{#1}}                    %KT
\def\plotone_reduction#1#2{\centering \leavevmode        %KT
\epsfxsize=#2\columnwidth \epsfbox{#1}}                  %KT
\def\plottwo#1#2{\centering \leavevmode                  %KT
\epsfxsize=.45\columnwidth \epsfbox{#1} \hfil            %KT
\epsfxsize=.45\columnwidth \epsfbox{#2}}                 %KT
\def\plotfiddle#1#2#3#4#5#6#7{\centering \leavevmode     %KT
\vbox to#2{\rule{0pt}{#2}}                               %KT
\special{psfile=#1 voffset=#7 hoffset=#6 vscale=#5 hscale=#4 angle=#3}} %KT
\makeatother


\begin{document}

\begin{center}
{\huge {\it The \ath\ User's Guide }} \vspace{1in} \\
{\Large James M. Stone, Thomas A. Gardiner} \\
{\large Department of Astrophysical Sciences \\ Princeton University \\
Princeton, NJ 08540} \vspace{0.5in} \\
{\Large Peter J. Teuben} \\
{\large Department of Astronomy \\ University of
Maryland \\ College Park MD 20742-2421} \vspace{0.5in} \\
and \vspace{0.5in} \\
{\Large John F. Hawley} \\
{\large Department of Astronomy \\ University of
Virginia \\ PO Box 3818 University Station \\ Charlottesville, VA 22903} \vspace{1in} \\
\end{center}
\newpage

\section{Introduction}

{\it Athena} is a grid-based code for astrophysical gas dynamics
developed with support of the NSF Information Technology Research (ITR)
program.  This {\it User's Guide} describes version 3.0 (hereafter
referred to as \ath); the third publicly released version of the code.

The \ath\ code contains algorithms for the following:
\begin{itemize}

\item compressible hydrodynamics and ideal MHD in one, two, or three spatial dimensions,

\item ideal gas equation of state with arbitrary $\gamma$ (including 
$\gamma = 1$, an isothermal EOS),

\item second- or third-order reconstruction using the characteristic variables
(first-order interpolation is also available),

\item numerical fluxes computed using a variety of Riemann solvers (including
various solvers based on HLL fluxes, and Roe's linearization),

\item the ability to add source terms due to a static gravitational potential,

\item parallelization based on MPI.

\end{itemize}
It is strongly advised to use the latest release of
the code for research problems (even those in one-dimension) to take
advantage of improvements and potential bug fixes.

There are four basic sources of documentation for \ath:
\begin{enumerate}

\item {\it The Method Papers:} There are four in all: Gardiner \& Stone
(2005; 2007), Stone \& Gardiner (2007), and Stone et al. (2007).  Each of
these are available either on ADS or astro-ph (by end of 2007).

\item {\it The User's Guide:} (this document) gives an overview of how to
install, configure, compile, and run \ath\ and visualize the resulting output.

\item {\it The Programmers's Guide:} gives a basic introduction to the 
data structures, variable names, grid definitions, and code structure.

\item {\it Web-based Tutorials:} contains instructions
for running problems from the \ath\ test suite, including examples of results.
See {\tt http://www.astro.princeton.edu/~jstone/athena.html}.

\end{enumerate}
Users of \ath\ should have a basic, working knowledge of the Unix
operating system, access to a C compiler, and a graphics package for
plotting or animating one-, two-, and three-dimensional data.  Some familiarity
with code management using Makefiles is helpful but not necessary.

The code has been developed using the GNU development tools,
maintaining strict adherence to ANSI standards, thus it should be possible
to configure, compile, and run the code on any platform that supports these
standards.  It has been tested on Linux, MacOSX, and Solaris.

\subsection{Changes from {\tt athena2.0}}

The last publicly released version of the code was v2.0.  The current
version differs primarily in that it implements two different unsplit,
three-dimensional algorithms; one based on CTU (Gardiner \& Stone 2007),
and one based on an algorithm due to van Leer (Stone \& Gardiner 2007).

In addition, there are a number of structural changes to the code, including:
(1) some files in {\tt /src} and {\tt src/prob} are renamed, and many new files are added,
(2) many new tests and scripts have been added in {\tt /tst}
(3) many options have changed in the configure script,
(4) new data output modes and options have been added.
(5) parallelization using domain decomposition based on MPI and controlled
by new parameters in the input file has been added.

\subsection{Future versions}

This is the last version of \ath\ released with support of the NSF
ITR program, and there is no schedule planned for future releases.
The current developmental version of the code includes many more
algorithmic extensions than in this release, such as static and
adaptive mesh refinement, self-gravity, and radiation transfer.
It is likely that some of these extensions will be released in the future,
albeit on an irregular schedule.

\section{Quick Start}

To install, configure, compile, and run the code do the following.
\begin{enumerate}

\item Download\footnote{from {\tt http://www.astro.princeton.edu/~jstone/athena.html}}, uncompress, and untar the source code distribution file.

\item Create the configure script by running {\tt autoconf} in the
{\tt athena3.0} directory.

\item Test the install by running {\tt configure}; {\tt make all};
{\tt make test}.

\item If there are no errors in the previous step the install was
successful.  The code can now be re-configured, re-compiled, and used to run any
of the test problems in {\tt /src/prob}.

\end{enumerate}

\section{Getting Started}

\subsection{Obtaining and Installing \ath}

The source code for \ath\ can be downloaded as a gzipped tar file from the
web.  To install and run the code requires only a C compiler.

After downloading the tar file, uncompressing and untarring it,
the following directory structure should be created:

\begin{verbatim}
/athena3.0
          /doc            documentation, manuals
          /src            source code, and include files
              /prob       problem files (see /src/problem.c for a symbolic link)
          /tst            various input files for tests
              /1D-hydro
              /1D-mhd
              /2D-hydro
              /2D-mhd
              /3D-hydro
              /3D-mhd
          /vis            visualization tools and scripts
              /dx         OpenDX scripts
              /idl        IDL (rsinc.com) scripts
              /sm         Super Mongo scripts
              /vtk        code to join VTK legacy files
\end{verbatim}
In addition to the directories listed above (which are created when you
untar the source code), another directory will be created by the Makefile
when \ath\ is compiled for the first time, using {\tt make all}.

\begin{verbatim}
/athena3.0
          /bin           contains executable, created by Makefile
\end{verbatim}
(Trying to compile the code with {\tt make compile} before
{\tt make all} will result in an error since the {\tt bin} directory will
not yet exist.)

The {\tt athena3.0/doc} directory contains .pdf files of this document,
the {\em Programmer's Guide}, and the Method papers.  These documents serve as
the primary source of reference for the code, and should be consulted for
complete information.

\subsection{Configuring \ath}

After you have installed \ath\, the next step is to configure the
code for a specific problem.  To generate the {\tt configure} shell
script using the GNU {\tt autoconf} toolkit\footnote{autoconf: see {\tt
http://www.gnu.org/software/autoconf/}}, type {\tt autoconf} in the {\tt
athena3.0} directory.  If you wish to by-pass the configure script and work
with the Makefiles directly, see \S 3.54 below.

There are several basic functions served by the {\tt configure} script.
The first is to enable or disable {\it features} in the code, and to
choose between different {\it packages} implemented in \ath.  Configure
features are used when a particular option has only two choices:
enabled (``on") or disabled (``off"): examples include choosing whether
the executable uses single or double precision, or enabling or disabling
various data output formats.  Configure packages are used when an
option may have more than one choice.  Examples of packages include
the basic physics options (such as hydrodynamics or MHD, adiabatic or
isothermal equation of state, etc.), as well as the algorithm options
(order of accuracy for the reconstruction step, choice of Riemann solver,
etc.).  These package options are controlled at the source code
level using C precompiler macros.  The {\tt configure} script provides
a powerful way of setting these macros through a command line interface
that does not require the user to edit any special files.

More advanced features of the {\tt configure} script are to set compiler
and linker options and flags using environment variables, and to query the
system automatically to see that a C-compiler, linker, and any external
libraries necessary for compilation are installed and accessible.
Currently, only the latter of these features are utilized.

Once the {\tt configure} script has been created, it can be used
with the following
syntax
\begin{center}
{\tt configure [--enable-{\it feature}] [--disable-{\it feature}]
[--with-{\it package}={\it choice}]},
\end{center}
where {\it feature} and {\it package}
are valid options in \ath, and {\it choice} is the value to which
{\it package} is to be set.  The valid optional features in \ath\ are given in
Table 1, and the valid optional packages (including all possible choices and
their default values) are given in Table 2\footnote{The file {\tt configure.ac}
contains the information auto-conf needs to generate the configure script
with these options.}.

\begin{table}[ht]
\caption{Optional features controlled by {\tt configure} in \ath}
\begin{center}
\begin{tabular}{|c|c|c|} \hline \hline
FEATURE & DEFAULT & Comments \\ \hline
single &  disabled & computations performed in single precision (default is double) \\
debug  & disabled & compiles code with flags needed for debugger \\
ghost  & disabled & causes ghost zones to be written during output \\
mpi    & disabled & parallelization using MPI library \\
h-correction & disabled & H-correction to fix carbuncle problem 
\\ \hline
\end{tabular}
\end{center}
\\
\end{table}

\begin{table}[ht]
\caption{Optional packages controlled by configure in \ath}
\begin{center}
\begin{tabular}{|c|c|c|} \hline \hline
PACKAGE & CHOICE$^{a}$ & Comments \\ \hline
problem & {\it file-name} & use {\it file-name} in directory {\tt /src/prob} for initial conditions \\ \hline
gas    & hydro  & create code for hydrodynamics \\
       & {\bf mhd}    & create code for MHD \\ \hline
eos    & {\bf adiabatic} & use adiabatic equation of state \\
       & isothermal & use isothermal equation of state \\ \hline
flux & {\bf roe} & Roe's Riemann solver \\
     & force & FORCE flux \\
     & hlle & HLLE Riemann solver \\
     & hllc & HLLC Riemann solver (hydrodynamics only) \\
     & hlld & HLLD Riemann solver (MHD only) \\ \hline
order & 1 & use first-order spatial reconstruction \\
      & {\bf 2} & use second-order (piecewise-linear) spatial reconstruction \\
      & 3 & use third-order (piecewise-parabolic) spatial reconstruction \\ \hline
integrator & {\bf ctu} & corner transport upwind unsplit integrator in 3D \\
           & vl & van Leer unsplit integrator in 3D \\
\hline
\end{tabular} \\
\end{center}
$^{a}$ Default choices shown in bold.
\end{table}

Only one choice can be made for each optional package given in Table 2
(the choices are mutually exclusive).  The ``problem" package should be
set to the file name in the directory {\tt athena3.0/src/prob} that is
to be used by the code to initialize the problem of interest.  A variety
of choices are included for the test problems that can be run by \ath\
(the default problem file is {\tt athena3.0/src/prob/linear\_wave1d.c},
{\it i.e.} {\tt --with-problem=linear\_wave1d}), these are described in
more detail in \S 6.  Note that {\tt configure} creates a symbolic link
between {\tt problem.c} in {\tt athena3.0/src} and the appropriate file
in {\tt athena3.0/src/prob}.

The {\tt configure} script should be run in the root directory {\tt
/athena3.0}.  Running {\tt configure} with the help option ({\tt configure
--help}) gives more information, including a list of all optional features
and packages.

For example, to configure \ath\ to run an isothermal hydrodynamical shocktube
problem initialized with the function {\tt shkset1d.c} problem
using Roe fluxes and third-order interpolation in single precision, use the
following:
\begin{center}
{\tt configure --with-problem=shkset1d --enable-single --with-eos=isothermal --with-gas=hydro --with-order=3}
\end{center}

To configure \ath\ to run the linear wave test problem in 3D adiabatic
MHD using HLLD fluxes, the van Leer integrator, and second-order interpolation in double precision
parallelized with MPI, use the following:
\begin{center}
{\tt configure --with-flux=hlld --with-problem=linear\_wave3d --with-integrator=vl --enable-mpi}
\end{center}

When {\tt configure} runs, it creates a custom {\tt Makefile} for the
problem in the directory {\tt athena3.0/src} using the file {\tt
athena3.0/src/Makefile.in} as a template.  After successful execution,
{\tt configure} will echo the options that have been set (including all
the default values).

\subsection{Compiling \ath}

After running {\tt configure}, all that is required to compile the code
is to type {\tt make all} in the top level directory {\tt /athena3.0}
(within which the configure script is run).  This automatically creates
the directory {\tt athena3.0/bin}, which will contain the executable,
and runs make in the {\tt athena3.0/src} directory to compile and link
the code.  The top-level Makefile in the {\tt /athena3.0} directory also
contains other targets listed in Table 3.

\begin{center}
\begin{table}[ht]
\caption{Some Makefile targets in \ath}
\end{center}
\begin{tabular}{|c|c|} \hline \hline
TARGET & Comments \\ \hline
all & creates {\tt /athena3.0/bin} directory and compiles code \\
compile & compiles code \\
clean & removes .o files in {\tt /athena3.0/src} \\
help & prints help message \\
test & runs install test (see \S 10.1) \\
\hline
\end{tabular}
\end{center}
\end{table}

Normally the Makefiles should never be edited by hand.  However,
it is possible to edit the Makefile in the {\tt /athena3.0/src} directory to
change compiler flags (to improve optimization, for example)
rather than using
environment variables.  Just remember that the {\tt Makefile} is always 
overwritten every time {\tt configure} is run, so any custom changes may be
lost.

To make changes to the Makefile in the {\tt /athena3.0/src} that are permanent,
edit the template file {\tt /athena3.0/src/Makefile.in}.
For example, the best way to customize the compiler, options, flags,
and the path of local libraries is through the {\tt MACHINE=} option
on the make command line.  Currently, the options for several target machines are
included in {\tt Makefile.in}.  If no value for the {\tt MACHINE} option is
provided, the default is to use the {\tt gcc} compiler
with an optimzation level of {\tt -O3}.  By using
\begin{verbatim}
% make all MACHINE=ophir
\end{verbatim}
the Intel C compiler (icc) with the options
{\tt -O2 -xW -tpp7 -ipo -i\_dynamic -gcc-name=gcc32} will be used.  To add
a new target machine, copy one of the machine targets in {\tt Makefile.in},
rename it, and edit as appropriate. 

\subsection{By-passing configure}

Most of the physics options in \ath\ are controlled by precompiler macros.  The
complete set of valid macros (some of which are mutually exclusive) are
defined in the file {\tt /src/defs.h.in}.  
The configure script creates a header file {\tt /src/defs.h} which contains
the appropriate set of macro definitions required for the given problem.
However, one can by-pass the configure script by creating and editing the
{\tt defs.h} file by hand (be warned that running configure at some later time
will overwrite this file).

Similarly, the compilation step is controlled by a Makefile generated by
the configure script from {\tt /src/Makefile.in}.  To bypass the configure
script, a custom Makefile must be created by hand from this template.
Again, remember that the {\tt Makefile} is always
overwritten every time {\tt configure} is run, so any custom changes may be
lost.

\subsection{Running \ath}

After configuring and compiling \ath, there should be an executable
called {\tt athena} in the directory {\tt athena3.0/bin}.  There
are two steps to running the code: (1) editing parameters in the
input file, and (2) running the executable.  Editing the input file is 
described in more detail in the subsections below.

The \ath\ executable can be run using the {\tt -i} option to specify the name of
the input file.  For example, to run the Brio \& Wu shocktube use
the command
\begin{verbatim}
  % athena -i ../tst/1D-mhd/athinput.brio-wu
\end{verbatim}
The code will first echo the values of all input parameters to stdout.
During the main integration loop
it will print the cycle number and timestep, and
when it concludes it will print final diagnostic information.

A variety of command line options have been implemented in \ath.
A list is given by the {\tt -h} switch:
\begin{verbatim}
  % athena -h
Athena version 3.0 - 01-JAN-2007
  Last configure: Wed Jan  3 17:20:12 EST 2007

Usage: athena [options] [block/par=value ...]

Options:
  -i <file>       Alternate input file [athinput]
  -d <directory>  Alternate run dir [current dir]
  -h              This Help, and configuration settings
  -n              Parse input, but don't run program
  -c              Show Configuration details and quit
  -r <file>       Restart a simulation with this file

Configuration details:

 Problem:                 linear_wave1d
 Gas properties:          MHD
 Equation of State:       ADIABATIC
 Order of Accuracy:       2 (SECOND_ORDER)
 Flux:                    roe
 Unsplit 3D integrator:   ctu
 Precision:               DOUBLE_PREC
 Output Modes:
   Ghost Cells:           disabled
 Parallel Modes:
   MPI:                   MPI_SERIAL
 H-correction:            disabled
\end{verbatim}
The {\tt -d} option can be used to create a new directory in which
\ath\ will run and write the output files.  The {\tt -n} option is
useful for debugging any parsing errors, as it will dump the contents
of all parsed block/parameters.

A value for any of the valid parameter names can also be input from
the command line, this over-rides the values in the input file.
This, in combination with the {\tt -d} option, is
useful for parameter surveys.  The {\tt -c} option is useful for checking
the configuration parameters with which the exucutable was compiled.

\subsubsection{Editing the input file}

Run time parameters are set in an input file, usually given the name
{\tt athinput.}{\it problem-name}, where {\it problem-name} is a
string identifier.  Often this string is the same as the name of the
problem-generator, i.e. the function in {\tt athena3.0/src/prob} which
is used to initialize the data.  In some cases, a name which is more
specific to the problem at hand is used (since some problem-generators
can be used to initialize more than one problem).

As an example of an \ath\ input file, the file 
{\tt /athena3.0/tst/1D-mhd/athinput.brio-wu} is reproduced below.
Other examples can be found in the subdirectories in {\tt /athena3.0/tst/}.

\footnotesize
\begin{verbatim}
<comment>

problem = Brio & Wu shock tube
author  = M. Brio & C. C. Wu 
journal = J. Comp. Phys. 75, 400-422 (1988)
config  = --with-problem=shkset1d

<job>

problem_id      = Brio-Wu   # problem ID: basename of output filenames
maxout          = 3         # Output blocks number from 1 -> maxout

<output1>
out_fmt = tab               # Tabular data dump
dt      = 0.0025            # time increment between outputs

<output2>
out_fmt = hst               # History data dump
dt      = 0.0025            # time increment between outputs

<output3>
out_fmt = bin               # Binary data dump
dt      = 0.0025            # time increment between outputs

<time>

cour_no         = 0.8       # The Courant, Friedrichs, & Lewy (CFL) Number
nlim            = 10000     # cycle limit
tlim            = 0.1       # time limit

<grid>

Nx1             = 800       # Number of zones in X1-direction
x1min           = 0.0       # minimum value of X1
x1max           = 1.0       # maximum value of X1
ibc_x1          = 2         # inner (X1) boundary flag
obc_x1          = 2         # outer (X1) boundary flag

Nx2             = 1         # Number of zones in X2-direction
x2min           = 0.0       # minimum value of X2
x2max           = 1.0       # maximum value of X2
ibc_x2          = 2         # inner (X2) boundary flag
obc_x2          = 2         # outer (X2) boundary flag

Nx3             = 1         # Number of zones in X3-direction
x3min           = 0.0       # minimum value of X3
x3max           = 1.0       # maximum value of X3
ibc_x3          = 2         # inner (X3) boundary flag
obc_x3          = 2         # outer (X3) boundary flag

<parallel>

NGrid_x1 = 1
NGrid_x2 = 1
NGrid_x3 = 1

<problem>

gamma           = 2.0       # gamma = C_p/C_v

shk_dir         = 1         # Shock Direction -- (1,2,3) = (x1,x2,x3)

dl              = 1.0       # density on left half of grid
pl              = 1.0       # pressure
v1l             = 0.0       # X-velocity
v2l             = 0.0       # Y-velocity
v3l             = 0.0       # Z-velocity
b1l             = 0.75      # X-magnetic field
b2l             = 1.0       # Y-magnetic field
b3l             = 0.0       # Z-magnetic field

dr              = 0.125     # density on right half of grid
pr              = 0.1       # pressure
v1r             = 0.0       # X-velocity
v2r             = 0.0       # Y-velocity
v3r             = 0.0       # Z-velocity
b1r             = 0.75      # X-magnetic field
b2r             = -1.0      # Y-magnetic field
b3r             = 0.0       # Z-magnetic field
\end{verbatim}
\normalsize

Note the syntax of the parameter specification used in this file.
Parameters are grouped into named {\it blocks}, with the name of each
block appearing on a single line within angle brackets.  Block names
must always appear in angle brackets on a separate line (although the
blank lines above and below the block names are not required).

Below each block name is a list of parameters, with syntax
\begin{center}
 {\it parameter-name} = value [\# comments]
\end{center}
White space after the parameter name, after the `=', and before the
`\#' character is ignored.  Everything after (and including) the `\#'
character is also ignored.  Only one parameter value can appear per
line.  Comment lines (i.e. a line beginning with `\#') are allowed for
documentation purposes.  A maximum number of 256 characters is permitted
per line in the input file.  Both block names and parameter names are
case sensitive.

The input file is read by a very flexible parser written for \ath\
({\tt /athena3.0/src/par.c}).  The entire input file is read at the
very beginning of the main program, and the parameter names and their
values stored in memory.  Thereafter, these values can be accessed as
necessary by any function at any time during execution.  The parser
allows the parameter names to appear in any order within a named
block, extra (or misspelled) parameter names will be parsed and never
used.  There are no default values for any of the run-time parameters
in the input file; each parameter must be supplied a value through the
input file.  If a value is requested from the parser but its name does
not exist, the parser will print an error message and terminate the
execution of the program.  In this way, both missing or misspelled
parameter names will be detected at run time.  The parameters may be
integers, floating point numbers, or strings.  The parser will do
automatic type conversion, for example converting floating point
numbers to double precision if necessary (though the user is expected
to know the basic difference between real, integer, and string data
types).  Parameter values can also be set at run time through the
command line, which provides a very flexible way of testing the code
and running parameter searches (see \S 5.2),
using the syntax ``{\it block/parameter=value}''.

Below we describe each of the parameter blocks in the input file,
and the parameters they contain.

\subsubsection{The {\tt <comment>} block}

Provides self-documentation of the file.  The variables in this block
are not used in the code.

\subsubsection{The {\tt <job>} block}

Parameters in this block control properties of the jobs run by \ath.
They are accessed by the function {\tt main.c}.
\begin{itemize}

\item {\bf problem\_id:}
string added as basename of output filenames (see \S 3).  Usually same
as {\it problem-name} used in input file.  There is no maximum length
for this name\footnote{Although remember that the maximum length of a
line in the input file is 256 characters.}.

\item {\bf maxout:} Specifies how many output blocks will be read from
input file.  Output
blocks {\tt<output1>} through {\tt<outputN>} where {\tt N} = maxout
are scanned for valid output descriptions.  Missing output
blocks are permitted.

\end{itemize}

\subsubsection{The {\tt <output\#>} block}

Parameters in these blocks control the writing of ``outputs'',
e.g. data dumps, images, etc.
\begin{itemize}

\item {\bf out:} Variable to image for {\tt pgm, ppm, fits} output formats.
Currently accepted values are:
{\tt all, d, M1, M2, M3, E, B1c, B2c, B3c, ME, V1, V2, V3, P, S, cs2}.
Not required for {\tt bin, dx, hst, tab, rst, vtk} output types 
(which can only dump all rather than selected variables).

\item {\bf out\_fmt:} Output format, e.g.  
{\tt bin, dx, hst, tab, rst, vtk, fits, pdf, pgm, ppm}

\item {\bf dat\_fmt:} Optional field for controlling the format string used 
to write tabular output files, e.g. {\tt \%12.5e}.  This value should
not appear in quotes and no white space should be present.

\item {\bf dt:} Time increment between outputs in problem time.

\item {\bf id:} Any string, added to label output filenames.

\item {\bf dmin/dmax:} max/min applied to output (useful for images).

\item {\bf palette:} Color palette for images.  Currently available palettes
are {\tt rainbow, jh\_colors, idl1, idl2, step8, step32, heat}.

\item {\bf ix1, ix2, ix3:} Range of indices in x1, x2, or x3 directions over
which data is averaged.  For example {\tt ix1=:} will average over whole x1 axis
and dump a 2D array.  {\tt ix1=5:} will average from 5 to end. {\tt ix1=:10}
will average from start to 10. {\tt ix1=5:10} will average from 5 to 10.
{\tt x1=5} will extract the single plane at i index 5.

\item {\bf usr\_expr\_flag:} Set to 1 to use user defined expression to compute
output quantity, see \S X.

\end{itemize}

\subsubsection{The {\tt <time>} block}

Parameters in this block control times in a job (such as ending time).
They are accessed by the function {\tt main.c}.
\begin{itemize}

\item {\bf tlim:} Time to stop integration, in units defined by problem

\item {\bf nlim:} Maximum number of cycles of the main loop before stopping.
Set to -1 to stop only on time limit {\tt tlim}.

\item {\bf cour\_no:}  CFL number, must be less than 1.0 for 1D and 2D, 0.5
for 3D.

\end{itemize}

\subsubsection{The {\tt <grid>} block}

Parameters in this block control the properties of the grid. 
They are accessed by the function {\tt init\_grid\_block.c}.
\begin{itemize}

\item {\bf Nx1, Nx2, Nx3:} number of grid cells in the x1-, x2-, and x3-directions.

\item {\bf x1min, x2min, x3min:} x1-, x2-, x3-coordinate of left-edge of first cell

\item {\bf x1max, x2max, x3max:} x1-, x2-, x3-coordinate of right-edge of last cell.
The computational domain in the x1-direction spans $x1_{max}-x1_{min}$, the grid
spacing is $\Dx1=(x1_{max}-x1_{min})/Nx1$, and the center of the
first cell is located at $x1=x1_{min} + \Dx1/2$. Also, $x1_{max} >
x1_{min}$ is required.  Similarly for the computational domain in the 
x2- and x3-direction.

\item {\bf ibc\_x1, obc\_x1:} integer flags for boundary conditions applied
at ``inner" (left) and ``outer" (right) edges of grid.  Currently three
values are implemented: 1 = reflecting, 2 = inflow and outflow (projection), 
and 4 = periodic.  See \S 5 for more information.

\item {\bf ibc\_x2, obc\_x2:} Analogous parameters for the x2-direction.

\item {\bf ibc\_x3, obc\_x3:} Analogous parameters for the x3-direction.

\end{itemize}

\subsubsection{The {\tt <parallel>} block}

Parameters in this block control the decomposition of the computational
domain into MPI blocks.  The domain can be decomposed in any coordinate
direction, and into an arbitrary number of blocks.  This allows slab, pencil,
and block decompositions.
\begin{itemize}
\item {\bf NGrid\_x1:} Number of MPI blocks in the x1-direction.
\item {\bf NGrid\_x2:} Number of MPI blocks in the x2-direction.
\item {\bf NGrid\_x3:} Number of MPI blocks in the x3-direction.
\end{itemize}
This block can be omitted for serial jobs, or
the number of MPI blocks can be set to one in each dimension (as in the
example).

\subsubsection{The {\tt <problem>} block}

Parameters in this block are accessed by the problem-generator,
and therefore depend on the problem being run.  For example, the 
problem-generator {\tt athena3.0/src/prob/shkset1d.c}
(which is used for the Brio \& Wu test problem)
requires the following parameter values in the {\tt <problem>} block:
\begin{itemize}
\item {\bf gamma:} ratio of specific heats used in equation of state
\item {\bf *l:} values of variable * in left-state
\item {\bf *r:} values of variable * in right-state
\end{itemize}
The {\bf *l} and {\bf *r} parameter names are specific to the Brio \&
Wu shocktube problem.  In general, the input file for other problems
will have different variable names in the problem block.

\section{Data output formats}

As described above in \S 3.5.3, data output in the \ath\ code is
controlled by the {\tt <output>} blocks in the input file.  There should
be one block for each type of data output required.  There is no limit on
the total number of outputs.  Output filenames use a naming convention
{\it basename-id\#.dumpid.outid.type}, where the {\tt basename} is inherited
from the {\tt <job>problem\_id} parameter, the {\it -id\#} labels the
processor id for jobs run with MPI (the root process does not contian an
id, nor is an id present for serial jobs), the {\it dumpid} is a zero
filled unsigned integer with {\tt <job>numdigits}\footnote{currently
fixed at four}, the {\it outid} denotes the block number in the input
file which generated the output (necessary because in some cases more
than one block can generate the same type of dump), and the {\it type}
denotes the output format ({\tt bin, tab, hst, vtk, rst, pdf, pgm, ppm, fits}).
(note that history dump filenames do not include a {\it dumpid} or
{\it outid}). 

The meaning of the parameters in the {\tt <output>} block has already been
described in \S 2.5.3.  Below we provide more information about each of the
output types.
\begin{enumerate}

\item {\bf History dumps:} ({\em type} = {\tt hst} Contains a formatted
table of a variety of volume integrated values, with one line in the
table created every {\tt dt} in time (where {\tt dt} is set in the
corresponding {\tt <output>} block).  Thus, at the end of execution, the
output file contains $tlim/dt$ lines which form a time-history of these
quantities.  The file is created by the function {\tt dump\_history.c};
more (or problem specific) quantities can be added by editing this file.
The data is appended to the file each time the {\it dump\_history()}
function is called.

\item {\bf Binary dumps:} ({\em type} = {\tt bin} Contain an unformatted
write of all dependent variables over all active zones.  If the {\tt dx}
option is enabled by configure, then an OpenDX header file with the same
name as the corresponding binary file but with the extension {\tt .dx}
will be created.  This header file allows binary dumps to be read by
OpenDX networks (see \S7.2).  A new file is created with a time interval
of {\tt dt} in the corresponding output block.  Created by the function
{\tt dump\_binary.c}.

\item {\bf Tabular dumps:} ({\em type} = {\tt tab} Contain a formatted
table of all dependent variables overall all zones.  A new file is
created with a time interval of {\tt dt} set in the output block.
Created by the function {\tt dump\_table.c}.  Useful for making 1D plots.

\item {\bf  ppm images:} ({\em type} = {\tt ppm) Two dimensional images of
the variable set in the output block using the {\tt out} variable name.
Global scaling can be set using the parameters {\tt dmin} and {\tt
dmax} in the output block, otherwise each image is scaled independently.
A default color palette ({\tt rainbow}) is used.  Created by the function
{\tt output\_ppm.c}.

\item {\bf  pgm images:} ({\em type} = {\tt pgm) Grayscale images,
written in pgm format.  Created by the function {\tt output\_pgm.c}.

\item {\bf Probability distribution functions:} ({\em type} = {\tt pdf)
Outputs PDF of selected variables in tabular form.  Created by the
function {\tt output\_pdf.c}.

\item {\bf  fits images:} ({\em type} = {\tt fits) Same as ppm images,
but written in fits format.  Created by the function {\tt output\_fits.c}.

\item {\bf vtk files:} ({\em type} = {\tt vtk) Similar to binary dumps,
but output written in VTK legacy format.  Useful for 3D simulations.
Created by the function {\tt dump\_vtk.c}.

\item {\bf Restart dumps:} ({\em type} = {\tt rst) Creates a binary dump
of all variables (in double precision if necessary) that can be used to
restart a simulation.  The start of the restart file contains the entire
input file in ASCII.  For jobs run in parallel with MPI, there will be
one restart file per process, and the restarted job must contain the
same number of processors.  See the next subsection for further details.

\end{enumerate}

It is important to note that {\bf output files in \ath\ will always be
silently overwritten!} 

\subsection{More on Restarts}

Restart dumps (sometimes called {\em checkpoints}) are useful when a 
calculation must be continued from a previous point.  The files contain
enough information, and with the necessary accuracy, that a restart calculation
generates {\em identical} data (to all significant digits) to a calculation run
continuously.  \ath\ defines its
own format for restart files.  The file {\tt restart.c} contains all
the functions needed to read and write these files.

To write a restart file, add the following {\tt <output>} block to the
input file:
\begin{verbatim}
<output2>
out_fmt = rst               # Restart dump
dt      = 1.0            # time increment between outputs
\end{verbatim}
Note that {\tt job/maxout} must be greater than or equal to two in this example.
Of course, {\tt dt} is set to give the desired output frequency of files
(usually writing one restart dump every 6 hours of wall clock time is useful).

If the problem contains special, user-defined data, this must be added to the
restart dumps.  \ath\ provides a mechanism for automatically adding such data.
In the problem generator, two functions are provided:
\begin{verbatim}
void problem_write_restart(Grid *pG, Domain *pD, FILE *fp)
{
  return;
}

void problem_read_restart(Grid *pG, Domain *pD, FILE *fp)
{
  return;
}
\end{verbatim}
Generally these functions are empty, but if necessary they can be used to read
and write extra parameters, or set problem-specific boundary conditions
on restart, etc.  The problem generator {\tt rt.c} contains an example.

To read a restart file, the {\tt -r} command is used on the command line:
\begin{verbatim}
% athena -r myfile.rst
\end{verbatim}
Note that an input file, specified by {\tt -i myinput}, is not needed for
restarts.  This is because the restart file contains the original input file,
in ASCII format, at the beginning, from which all the necessary parameters
are read by {\tt par.c} on restart.  This also makes restart files self-documenting: the values of input parameters used in the calculation that generated
the restart file can be read with an editor.  If an input file is specified
along with a restart
\begin{verbatim}
% athena -r myfile.rst -i myinput
\end{verbatim}
Then the values in {\tt myinput} overwrite the values stored in the restart file
itself.  Alternatively, values in the input file can be overwritten using the
command line, as usual, for example:
\begin{verbatim}
% athena -r myfile.rst time/tlim=20.0
\end{verbatim}
One parameter that frequently needs to be changed in a restart is 
{\tt time/tlim}.

\subsection{Adding user-defined outputs}

It is also fairly easy to add entirely new data output modes using
function pointers. This can be accomplished in two steps.
The first step is to write a new output function in the file
containing the problem generator.  Suppose for example that the new
output function is called {\tt special\_output}, it must have the
following prototype
\begin{verbatim}
void special_output(Grid *pGrid, Domain *pDomain, Output *pOut);
\end{verbatim}
For details on the information contained in the {\tt Grid}, {\tt Domain},
or {\tt Output} structures, see the {\it Programmer's Guide}.  The second step
is to enroll this function by adding a call to {\tt
data\_output\_enroll} in the {\tt problem} routine.  The {\tt
data\_output\_enroll} function has the following prototype.
\begin{verbatim}
void data_output_enroll(Real time, Real dt, int num, const VGFunout_t fun,
                        const char *fmt, const Gasfun_t expr, int n,
                        const Real dmin, const Real dmax, int sdmin, int sdmax);
\end{verbatim}
The arguments to this function serve the following purpose.
\begin{itemize}

\item {\bf time:} The current simulation time.

\item {\bf dt:} The time interval between outputs.

\item {\bf num:} The initial data output number.

\item {\bf fun:} The name of the output function (a function pointer).  In
  the example above this is {\tt special\_output}, but it could also
  be say {\tt output\_ppm} for making images of some quantity.

\item {\bf fmt:} This is an optional format string used, for example,
  by {\tt dump\_table}.

\item {\bf expr:} The name of the function (a function pointer) of the
  quantity to be imaged when using an image type output routine,
  e.g. \{{\tt output\_ppm, output\_pgm, output\_fits}\}.

\item {\bf n}: Currently, image type outputs contain the string ``out\#'' 
in their file-name where the number ``\#'' is replaced with the argument 
{\bf n}.

\item {\bf dmin, dmax:} When making image type outputs, the data can 
either be auto-scaled to the min/max of the each image, or scaled to
the fixed values {\bf dmin / dmax}.

\item {\bf sdmin, sdmax:} Logical flags which indicate whether to use
auto-scaling ({\bf sdmin / sdmax} = 0) or to use the fixed scales
({\bf sdmin / sdmax} != 0).

\end{itemize}

In the simplest case the call to {\tt data\_output\_enroll} could take 
this form, where unused arguments are set to 0, or {\tt NULL}.
\begin{verbatim}
data_output_enroll(pGrid->time,0.1,0,special_output,NULL,NULL,0,0.0,0.0,0,0);
\end{verbatim}
As a more complex example, the following generates a series of ``ppm''
images of the result of the function {\tt expr\_dV3} scaled from
``dmin'' to ``dmax'' on a time interval ``dt'' with the string
``out-1'' in the file name.
\begin{verbatim}
data_output_enroll(pGrid->time,dt,0,output_ppm,NULL,expr_dV3,-1,dmin,dmax,1,1);
\end{verbatim}

\section{Specifying Boundary Conditions}

As described in \S 3.5.5, integer flags can be used to specify a limited set
of boundary conditions automatically in \ath.  The actual implementation of
the boundary conditions uses function pointers.  The
flags are used to enroll the appropriate default 
functions from the complete list in {\tt /src/set\_bvals.c}.  Each of these
functions sets quantities in the ghost zones according to the 
algorithm selected by the value of the flag.

The use of function pointers makes adding new boundary conditions for
specific problems quite easy.  For example, to add a new problem-specific
boundary condition along the inner X1 boundary, the user would (1)
write a new function which sets the values in the ghost zones in the
same file as the problem generator, and (2) enroll this new function by
adding the following line at the end of the problem generator
\begin{verbatim}
  set_bvals_fun(right_x1,special_bc_function_name);
\end{verbatim}

\noindent
where {\tt special\_bc\_function\_name} is the name of the special
function written in step (1).  The first argument of {\tt set\_bvals\_fun}
specifies the boundary on which the special function is enrolled; use
{\tt left\_x1} or {\tt right\_x1} for the inner or outer x1-boundary,
and similarly {\tt left\_x2} or {\tt right\_x2} specifies the inner or
outer x2-boundary respectively, and {\tt left\_x3} or {\tt right\_x3}
specifies the inner or outer x3-boundary respectively.  As examples,
users should look in the {\tt dmr.c}, {\tt noh2d.c}, and {\tt shkset3d.c}
problem generators; each contains special boundary functions enrolled
in this fashion.

Users should also note the following:

\begin{enumerate}

\item Boundary condition flags in the input file are only required for 
directions in which the grid is integrated.  That is, if {\tt Nx1>1}
and {\tt Nx2=1}, then only ibc\_x1 and obc\_x1 are required in the
input file.  The parameters ibc\_x2 and obc\_x2 may be present, but
their value will not be checked.

\item If the user enrolls a boundary condition routine for say the inner
x1-boundary, the boundary condition flag ibc\_x1 in the parameter file
is not required.  Again it may be in the parameter file, but its value
will not be checked.

\end{enumerate}

\section{Problem Generators Included in \ath}

A large number of problem generators are included in the {\tt /src/prob}
directory.  The complete list is
\begin{verbatim}
blast.c      dmr.c            lw_implode.c   rotor.c     shu-osher.c
carbuncle.c  field_loop.c     noh.c          rt.c        twoibw.c
cpaw1d.c     linear_wave1d.c  orszag-tang.c  shkset1d.c
cpaw2d.c     linear_wave2d.c  pgflow.c       shkset2d.c
cpaw3d.c     linear_wave3d.c  README         shkset3d.c
\end{verbatim}
The {\tt README} file in this directory describes the purpose of each
problem.

\section{Source terms due to a static potential}

The treatment of source terms in \ath\ is significantly different than
previous versions.  Now, only source terms due to a static gravitational
potential are allowed.  Future versions will include self-gravity.

To include a static gravitational potential in calculations,
a user defined function should be specified in the problem generator file,
for example
\begin{verbatim}
static Real grav_acc(const Real x1, const Real x2, const Real x3);
\end{verbatim}
The argument to the function should be the $x-$, $y-$, and $z-$coordinates
at which the gradient of the potential is to be evaluated.  The function is then enrolled
into the integrator using pointers, called {\tt x1GracAcc}, {\tt x1GracAcc},
and {\tt x1GracAcc} respectively for gradients of the potential in the
$x-$, $y-$, and $z-$directions.  These pointers are defined in
{\tt src/globals.h}.  To enroll the user-defined function that computes
the acceleration, add the line
\begin{verbatim}
  x3GravAcc = grav_acc;
\end{verbatim}
anywhere in the problem generator file.

The problem files {\tt pgflow.c} and {\tt rt.c} are good examples
of how to include source terms in your own applications.  In particular,
{\tt pgflow.c} sets up a stringent test of gravitational source terms.

\section{Running \ath\ on multiple processors using MPI}

\ath\ is parallelized using domain decomposition based on the
Message Passing Interface\footnote{http://www-unix.mcs.anl.gov/mpi/} (MPI).
The code can be run on any distributed memory cluster (or any multiple
processor system) on which MPI is installed using the following steps.

Firstly, during the configure step, the MPI option must be enabled via
\begin{verbatim}
% configure --enable-mpi
\end{verbatim}
This ensures all the apropriate precompiler macros are set to ensure the
appropriate MPI code is included.

Nest, during the compile step, the appropriate MPI libraries must be
linked.  Perhaps the easiest way to achieve this is to add an option
to {\tt src/Makefile.in} specifying the compiler, compiler options, linker,
and libraries specfic to the the target machine.  For example, using
\begin{verbatim}
% make all MACHINE=hydra
\end{verbatim}
uses the appropriate compiler and MPI libraries for a Beowulf cluster
at Princeton Universty called 'hydra'.  By copying the options for hydra
to a new target machine 'mymachine', editing them as appropriate, and
then compiling with
\begin{verbatim}
% make all MACHINE=mymachine
\end{verbatim}
should produce the apppriate executable.

Next, the input file for the problem of interest must be edited to add
a {\tt <parallel>} block with that specifies the desired domain decomposition.
For example, the following block in the input file
\begin{verbatim}
<parallel>

NGrid_x1 = 1
NGrid_x2 = 2
NGrid_x3 = 3
\end{verbatim}
will result in slab decomposition with two blocks in the $y-$direction and
three in the $z-$direction.  The total number of processors needed to run this
job is six.  Any decomposition is allowed, although there can be no fewer than
four active zones along any direction in any MPI block. 

Finally, the MPI job must be run, usually using the {\tt mpiexec} 
or {\tt mpirun} command.  The number of processors used must be specified
(e.g. through the command line using {\tt -np \#}, and this number must agree
with the number of MPI blocks specified in the {\tt <parallel>} block in the
input file, or \ath\ will print an error message and terminate.  A useful
script for the Parallel Batch System (PBS) which is often used to schedule
jobs on parallel clusters is included in the {\tt athena3.0/doc} directory.

Note that data generated by MPI parallel jobs will be written to seperate files
for each process (except for history or pdf files, which contain the
appropriate MPI calls to do global sums).  A useful program for joining
together multiple vtk files generated by a parallel job is
included in {\tt athena3.0/vis/vtk}.

\section{Visualizing output}

\ath\ does not come with a default graphics package.  Instead, the user must
decide which visualization package is best suited to their needs, output the
data in a format which can be read by this package, and then proceed.
As a start, rudimentary
scripts for several different graphics packages are supplied with the source
code; future versions may incorporate more sophisticated visualization
tools.  The following subsections describe useful visualization packages for
\ath\ data files (the discussion assumes the code has already been run to
produce output).

\subsection{IDL procedures}

The IDL (Interactive Data Language)\footnote{see also: {\tt
http://www.rsinc.com}} package can read the binary dump files.
A simple procedure for reading \ath\ binary dumps is included in {\tt
athena3.0/vis/idl}; to run this procedure you will need IDL installed on
your system.  (Note that binary dumps must be created with the fortran
option {\bf disabled} to be compatible with IDL.)  From the {\tt
athena3.0/bin} directory, use the following.
\begin{verbatim}
% idl
IDL> .run ../vis/idl/pltath.pro 
IDL> readbin,'Brio_Wu.0040.bin'
IDL> six_plot
\end{verbatim}
A variety of procedures are included in the {\tt pltath.pro} file, including 
a procedure to read binary files ({\tt readbin}), and make simple plots.

\subsection{OpenDX networks}

The OpenDX\footnote{see also: {\tt http://www.opendx.org}} package can
read our binary dump files, provided the {\tt .dx} header files exist.
This requires \ath\ be configured with the dx option enabled and of
course OpenDX must be installed on the system.

\subsection{supermongo}

A simple sm macro that can read tabular output from \ath\ is provided
in {\tt athena3.0/vis/sm}.

\subsection{vtk}

We have found the VisIt package\footnote{{\tt
http://www.llnl.gov/visit}} useful for plotting 3D data sets.  The VTK leagacy
format produced by \ath\ can be read by VisIt.  For data created with
executables parallelized with MPI, a C code that joins multiple files into
one is provided in {\tt athena3.0/vis/vtk}.  This is useful for jobs run
on massively parallel clusters.

\subsection{2D animations}

To make animations of 2D ppm images generated through an output block,
two possible routes are ImageMagick:

\begin{verbatim}
 % animate *.pgm
\end{verbatim}

or, alternatively, {\tt anim}:
\begin{verbatim}
 % ls Wind*pgm > list1
 % ppm2fli -g80x80 list1 Wind.fli
 % xanim Wind.fli

\end{verbatim}

\section{Examples of Running \ath}

\subsection{The \ath\ Benchmark}

To test the installation of \ath, a benchmark can be automatically
run using the Makefile.  This benchmark consists of running a linear
wave cnvergence test
on a grid of 512 zones, and
then computing the L1 error norm in the results compared to the
analytic solution.
If the benchmark fails
to run, or if the resulting error norm is large, then something has
gone wrong in the installation or in the compilation of the code.

To run the benchmark, use the following commands (in the \ath\
root directory; these steps assume the configure script has already been generated with {\tt autoconf}).
\begin{verbatim}
% configure
% make all
% make test
(cd tst/1D-mhd; ./run.test)
zone-cycles/cpu-second = 3.067215e+05
zone-cycles/wall-second = 3.055470e+05
L1 norm for density: 6.333390e-11
\end{verbatim}

\subsection{Running a 1D test problem with \ath: The Brio \& Wu shocktube}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a one-dimensional test problem, we show the steps required 
to run the Brio \& Wu shocktube.
Assuming the code has already been installed (see \S2), the first step is
to configure:
\begin{verbatim}
% cd athena3.0
% configure --with-problem=shkset1d
\end{verbatim}
The configure script will print a variety of diagnostic statements during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.0/bin} directory:
\begin{verbatim}
% cd bin
% athena -i ../tst/1D-mhd/athinput.brio-wu
\end{verbatim}
The code will print information about every timestep as it executes.  It
should generate 40 binary dumps named {\tt Brio\_Wu.*.bin}, 40 tabular
dumps named {\tt Brio\_Wu.*.tab},
as well as a history file {\tt Brio\_Wu.hst}.  There
are a variety of ways that the data in these files can be visualized; one
way is to use the IDL scipts included in {\tt athena3.0/vis/idl}.
\begin{verbatim}
% idl
IDL> .run ../vis/idl/pltath.pro
IDL> readbin,'Brio_Wu.0040.bin'
IDL> four_plot
\end{verbatim}

The resulting plots which should now appear on the screen is shown in Figure 1. 

\begin{figure}[htb!]
\plotone_reduction{figure1.ps}{0.8}
\caption{Results from Brio \& Wu shocktube test problem plotting using our
IDL routine {\tt four\_plot}}
\end{figure}

\subsection{Running a 2D test problem with \ath: The Orszag-Tang vortex}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a two-dimensional test problem, we show the steps required
to run the Orszag-Tang vortex test using the third order algorithm and the
HLLD fluxes.
Again, assuming the code has already been
installed (see \S2), the first step is to configure:
\begin{verbatim}
% cd athena3.0
% configure --with-order=3 --with-problem=orszag-tang --with-flux=hlld
\end{verbatim}
A variety of diagnostic statements will be printed during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.0/bin} directory:
\begin{verbatim}
% cd bin
% athena -i ../tst/2D-mhd/athinput.orszag-tang
\end{verbatim}
The code will print information about every timestep as it executes.  It
should generate 100 binary dumps named {\tt OrszagTang.*.bin}, 250 ppm 
images of the gas pressure named {\tt OrszagTang.*.out5.ppm},
as well as a history file {\tt OrszagTang.hst}.  There
are a variety of ways that the data in these files can be visualized; one
way is to use the IDL scipts included in {\tt athena3.0/vis/idl}.  To make a
contour plot of the pressure at time $t=0.5$, use the following:
\begin{verbatim}
% idl
IDL> .run ../vis/idl/pltath.pro
IDL> readbin,'OrszagTang.0050.bin'
IDL> contour,p,nlevels=30,/isotropic,xstyle=1,ystyle=1
\end{verbatim}

The resulting plot which should now appear on the screen is shown in Figure 2. 

\begin{figure}[htb!]
\plotone_reduction{figure2.ps}{0.8}
\caption{Contour plots of the gas pressure at time $t=0.5$ from
the Orszag-Tang test problem plotted using IDL.}
\end{figure}

It is also interesting to watch an animation of the pressure in the problem.
This can be done a variety of ways.  The {\tt .bin} files can be read and
animated used the procedures in the {\tt vis/idl/pltath.pro} file.
Alternatively, since \ath\ generates pm images directly as one of its
output modes, the images can be animated with packages such as {\tt xanim}
or {\tt animate} (part of ImageMagick).  For example, if ImageMagick is
installed on the system, try
\begin{verbatim}
% animate *.out5.ppm
\end{verbatim}

\subsection{Running a 3D test problem with \ath: Advection of a field loop}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a two-dimensional test problem, we show the steps required 
to run the advection of a field loop test.
Assuming the code has already been installed (see \S2), the first step is
Again, assuming the code has already been
installed (see \S2), the first step is to configure:
\begin{verbatim}
% cd athena3.0
% configure --with-order=3 --with-problem=field_loop --with-flux=hlld
\end{verbatim}
A variety of diagnostic statements will be printed during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.0/bin} directory: 
\begin{verbatim}
% cd bin
% athena -i ../tst/3D-mhd/athinput.field_loop4 grid/Nx1=64 grid/Nx2=64 grid/Nx3=64
parallel/NGrid_x1=1 parallel/NGrid_x2=1 parallel/NGrid_x3=1
\end{verbatim}
Note the input file for the field loop test rotated at an angle is run
({\tt iprob=4} in the {\tt <problem>} block).  Since the
default input file for this problem uses a $128^3$ grid, with a block
decomposition on 8 processors using MPI, the command line is used to overwrite
the input parameters to use a $64^3$ grid and only one processor.

It will take about 30 minutes for this calculation to complete on a 3.08 GHz
Xeon processor.  The run should generate three vtk files, and 250 ppm
images of the current density on a $x-y$ slice.  Using VisIt to make isosurface
plot of the magnetic energy density results in Figure 3 (with the
appropriate rotation).

\begin{figure}[htb!]
\plotone_reduction{figure3.ps}{0.8}
\caption{Surface plot of the magnetic energy, generated by VisIt, for
the advection of a rotated field loop in 3D.}
\end{figure}

\subsection{The \ath\ Test Suite}

Each of the problem generators in the {\tt /src/prob} subdirectory sets
up another test problem for \ath.  Further descriptions of these tests, and
examples of results from running \ath, can be found in the Athena code 
web pages, and in the Method papers.
  
\section{Running New Problems}

The \ath\ code can be used as a solver for new problems (i.e. problems that
are not initialized by the set of problem generators included in the source
code distribution).  The following steps are required.
\begin{enumerate}
\item Write a new function of type {\tt void} called {\tt problem} that initializes the problem.
The function must be contained in a file in the {\tt /src/prob} directory.
\item Write new functions called {\tt Userwork\_before\_loop} and 
{\tt Userwork\_after\_loop} (which may be no-ops if not needed) and include
them in the file containing {\tt problem}.  As the names suggest, these
functions can be used to perform special problem-dependent work before or 
after the main loop (see {\tt linear\_wave.c} for an example).
\item If special purpose boundary conditions are needed, write special
functions that implement them, and enroll them using the function
{\tt set\_bvals\_fun} (see \S 5).
\item If special purpose data output is needed, write special
functions that implement them, and enroll them using the function
{\tt data\_output\_enroll} (see \S 3).
\item Once the above is complete, configure and compile the code
using the appropriate physics options, and including the new problem
generator using {\tt --with-problem=}{\em new-name}.
\end{enumerate}

It is likely the {\em Programmer's Guide} will be needed to write a 
new problem generator to understand the data structures and names used
in \ath.  As a start, the problem generators in {\tt /src/prob} can be used
as examples.

\end{document}
